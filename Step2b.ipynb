{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9513,
     "status": "ok",
     "timestamp": 1649034359621,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "12f1ceb6-cf3c-4fc3-ab77-298c2d2ae985"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from cca_zoo.models import CCA\n",
    "\n",
    "# from cca_zoo.deepmodels import architectures\n",
    "# from cca_zoo.deepmodels import DVCCA, DCCA\n",
    "# from cca_zoo.deepmodels.architectures import BaseEncoder, Encoder, Decoder\n",
    "# from cca_zoo.deepmodels.dcca import _DCCA_base\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# making sure that the whole embedding tensor is printed in output\n",
    "torch.set_printoptions(threshold=10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bf6eb3a-48b0-457a-af11-86238c12c079"
   },
   "source": [
    "# Loading necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 116524,
     "status": "ok",
     "timestamp": 1649034476869,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "64504e16-fae1-40de-9dc2-ed26ef94f551"
   },
   "outputs": [],
   "source": [
    "# validation image and full text data\n",
    "img_val = torch.load(\"img_val.pt\")\n",
    "text_val = torch.load(\"text_val.pt\")\n",
    "\n",
    "# train image and full text data\n",
    "img_train = torch.load(\"img_train.pt\")\n",
    "text_train = torch.load(\"text_train.pt\")\n",
    "\n",
    "# test image and full text data\n",
    "img_test = torch.load(\"img_test.pt\")\n",
    "text_test = torch.load(\"text_test.pt\")\n",
    "\n",
    "#individual text test data\n",
    "ingredients_test = torch.load(\"test_ingredients.pt\")\n",
    "instructions_test = torch.load(\"test_instructions.pt\")\n",
    "title_test = torch.load(\"test_title.pt\")\n",
    "\n",
    "#individual text train data\n",
    "ingredients_train = torch.load(\"train_ingredients.pt\")\n",
    "instructions_train = torch.load(\"train_instructions.pt\")\n",
    "title_train = torch.load(\"train_title.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d139fea1"
   },
   "source": [
    "## Ranking function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1649034476870,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "12c7d566"
   },
   "outputs": [],
   "source": [
    "\"\"\"Retrieval ranking function for the learnt representations from the official code of im2recipe paper\"\"\"\n",
    "def ranker(im_vecs, instr_vecs, N = 1000, flag = \"image\"):\n",
    "    idxs = range(N)\n",
    "\n",
    "    glob_rank = []\n",
    "    glob_recall = {1:0.0,5:0.0,10:0.0}\n",
    "    for i in range(10):\n",
    "\n",
    "        ids = random.sample(range(0,len(im_vecs)), N)\n",
    "        \n",
    "        im_sub = im_vecs[ids,:]\n",
    "        instr_sub = instr_vecs[ids,:]\n",
    "\n",
    "        if flag == \"image\":\n",
    "            sims = np.dot(im_sub,instr_sub.T) # for im2recipe\n",
    "        else:\n",
    "            sims = np.dot(instr_sub,im_sub.T) # for recipe2im\n",
    "\n",
    "        med_rank = []\n",
    "        recall = {1:0.0,5:0.0,10:0.0}\n",
    "\n",
    "        for ii in idxs:\n",
    "\n",
    "            # name = ids_sub[ii]\n",
    "            # get a column of similarities\n",
    "            sim = sims[ii,:]\n",
    "\n",
    "            # sort indices in descending order\n",
    "            sorting = np.argsort(sim)[::-1].tolist()\n",
    "\n",
    "            # find where the index of the pair sample ended up in the sorting\n",
    "            pos = sorting.index(ii)\n",
    "\n",
    "            if (pos+1) == 1:\n",
    "                recall[1]+=1\n",
    "            if (pos+1) <=5:\n",
    "                recall[5]+=1\n",
    "            if (pos+1)<=10:\n",
    "                recall[10]+=1\n",
    "\n",
    "            # store the position\n",
    "            med_rank.append(pos+1)\n",
    "\n",
    "        for i in recall.keys():\n",
    "            recall[i]=recall[i]/N\n",
    "\n",
    "        med = np.median(med_rank)\n",
    "\n",
    "        for i in recall.keys():\n",
    "            glob_recall[i]+=recall[i]\n",
    "        glob_rank.append(med)\n",
    "\n",
    "    for i in glob_recall.keys():\n",
    "        glob_recall[i] = glob_recall[i]/10\n",
    "    \n",
    "    print (\"Mean median\", np.average(glob_rank))\n",
    "    print (\"Recall\", glob_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eb162482"
   },
   "source": [
    "## 2b Using Triplet Loss to train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1649034476871,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "6OX86xLvSBQP"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1649034477531,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "7XxJ79aiSBQV"
   },
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1649034477532,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "6LRrBHazSBQW"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HM8VRH7HiStf"
   },
   "source": [
    "### Negative Training Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 159,
     "status": "ok",
     "timestamp": 1649034477908,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "vxPhbgr7iRd9"
   },
   "outputs": [],
   "source": [
    "indices = list(range(0, len(text_train)))\n",
    "random.seed(0)\n",
    "random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 442,
     "status": "ok",
     "timestamp": 1649034478346,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "-PH2Fof3JKtM"
   },
   "outputs": [],
   "source": [
    "neg_text_train = [text_train[i] for i in indices]\n",
    "neg_title_train = [title_train[i] for i in indices]\n",
    "neg_ingredients_train = [ingredients_train[i] for i in indices]\n",
    "neg_instructions_train = [instructions_train[i] for i in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition and training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1649034478348,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "WHjMsKENSPF4"
   },
   "outputs": [],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, anchor_emb, positive_emb, negative_emb, transform=None):\n",
    "        self.anchor_emb = torch.as_tensor(np.array(anchor_emb))\n",
    "        self.positive_emb = torch.as_tensor(np.array(positive_emb))\n",
    "        self.negative_emb = torch.as_tensor(np.array(negative_emb))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anchor_emb)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.anchor_emb[idx], self.positive_emb[idx], self.negative_emb[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1649034478582,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "km0UIj52SPF4"
   },
   "outputs": [],
   "source": [
    "class EmbeddingNetwork(nn.Module):\n",
    "    def __init__(self, output_size, input_size=1024):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.layer2 = nn.Linear(512, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        return self.layer2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1649034478582,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "04O3sv9ZUG_q"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    # Utility function for timers\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
    "    \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1649034478583,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "99A73aTSUG_q"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, img_model, txt_model, criterion, optimizer, epoch):\n",
    "    print('Starting training epoch {}'.format(epoch))\n",
    "    img_model.train()\n",
    "    txt_model.train()\n",
    "    \n",
    "    batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    end = time.time()\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i, (anchor_emb, positive_emb, negative_emb) in enumerate(train_loader):\n",
    "    \n",
    "        # Use GPU if available\n",
    "        if use_gpu: \n",
    "            anchor_emb, positive_emb, negative_emb = anchor_emb.to(device), positive_emb.to(device), negative_emb.to(device)\n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # Run forward pass\n",
    "        out_anchor_emb = img_model(anchor_emb) \n",
    "        out_positive_emb = txt_model(positive_emb)\n",
    "        out_negative_emb = txt_model(negative_emb)\n",
    "        loss = criterion(out_anchor_emb, out_positive_emb, out_negative_emb) \n",
    "\n",
    "        # Compute gradient and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # Print model accuracy -- in the code below\n",
    "        running_loss += loss.item()\n",
    "        if i % 10000 == 0:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            running_loss = 0.\n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                'Time {batch_time.val} ({batch_time.avg})\\t'\n",
    "                'Data {data_time.val} ({data_time.avg})\\t'.format(\n",
    "                  epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                 data_time=data_time)) \n",
    "\n",
    "    print('Finished training epoch {}'.format(epoch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGpqTH3vSBQW"
   },
   "source": [
    "### Training dims = 512; all components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVzakDA6UG_p"
   },
   "source": [
    "#### im2recipe and recipe2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yadDS5RCUG_q"
   },
   "outputs": [],
   "source": [
    "train_dataset = EmbeddingDataset(img_train, text_train, neg_text_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_model = EmbeddingNetwork(512)\n",
    "# img_model= nn.DataParallel(img_model, device_ids=[2,3])\n",
    "img_model.to(device);\n",
    "\n",
    "txt_model = EmbeddingNetwork(512);\n",
    "# txt_model= nn.DataParallel(txt_model, device_ids=[2,3])\n",
    "txt_model.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(list(img_model.parameters()) + list(txt_model.parameters()), lr=1e-2, weight_decay=0.0)\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "# criterion = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu: \n",
    "    criterion = criterion.to(device)\n",
    "    img_model = img_model.to(device)\n",
    "    txt_model = txt_model.to(device)\n",
    "    \n",
    "best_losses = 1e10\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(train_loader, img_model, txt_model, criterion, optimizer, epoch)\n",
    "        \n",
    "  # Save checkpoint and replace old best model if current model is betterabs\n",
    "torch.save(img_model.state_dict(), 'triplet_checkpoints/img-model-full-512-epoch-{}.pth'.format(epoch+1))\n",
    "torch.save(txt_model.state_dict(), 'triplet_checkpoints/txt-model-full-512-epoch-{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0mMr_cyVXn6"
   },
   "source": [
    "#### im2title and title2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gO69Co-XtG-"
   },
   "outputs": [],
   "source": [
    "title_dataset = EmbeddingDataset(img_train, title_train, neg_title_train)\n",
    "title_loader = DataLoader(title_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_model_title = EmbeddingNetwork(512)\n",
    "# img_model_title = nn.DataParallel(img_model_title, device_ids=[2,3])\n",
    "img_model_title.to(device);\n",
    "\n",
    "txt_model_title = EmbeddingNetwork(512);\n",
    "# txt_model_title = nn.DataParallel(txt_model_title, device_ids=[2,3])\n",
    "txt_model_title.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(list(img_model_title.parameters()) + list(txt_model_title.parameters()), lr=1e-2, weight_decay=0.0)\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "# criterion = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu: \n",
    "    criterion = criterion.to(device)\n",
    "    img_model_title = img_model_title.to(device)\n",
    "    txt_model_title = txt_model_title.to(device)\n",
    "\n",
    "best_losses = 1e10\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(title_loader, img_model_title, txt_model_title, criterion, optimizer, epoch)\n",
    "        \n",
    "  # Save checkpoint and replace old best model if current model is betterabs\n",
    "torch.save(img_model_title.state_dict(), 'triplet_checkpoints/img-model-title-512-epoch-{}.pth'.format(epoch+1))\n",
    "torch.save(txt_model_title.state_dict(), 'triplet_checkpoints/txt-model-title-512-epoch-{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzdCubAmYl9T"
   },
   "source": [
    "#### im2ingredients and ingredients2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNR5CtQvY0pT"
   },
   "outputs": [],
   "source": [
    "ingredients_dataset = EmbeddingDataset(img_train, ingredients_train, neg_ingredients_train)\n",
    "ingredients_loader = DataLoader(ingredients_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_model_ingredients = EmbeddingNetwork(512)\n",
    "# img_model_ingredients = nn.DataParallel(img_model_ingredients, device_ids=[2,3])\n",
    "img_model_ingredients.to(device);\n",
    "\n",
    "txt_model_ingredients = EmbeddingNetwork(512);\n",
    "# txt_model_ingredients = nn.DataParallel(txt_model_ingredients, device_ids=[2,3])\n",
    "txt_model_ingredients.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(list(img_model_ingredients.parameters()) + list(txt_model_ingredients.parameters()), lr=1e-2, weight_decay=0.0)\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "# criterion = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu: \n",
    "    criterion = criterion.to(device)\n",
    "    img_model_ingredients = img_model_ingredients.to(device)\n",
    "    txt_model_ingredients = txt_model_ingredients.to(device)\n",
    "    \n",
    "best_losses = 1e10\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(ingredients_loader, img_model_ingredients, txt_model_ingredients, criterion, optimizer, epoch)\n",
    "        \n",
    "  # Save checkpoint and replace old best model if current model is betterabs\n",
    "torch.save(img_model_ingredients.state_dict(), 'triplet_checkpoints/img-model-ingredients-512-epoch-{}.pth'.format(epoch+1))\n",
    "torch.save(txt_model_ingredients.state_dict(), 'triplet_checkpoints/txt-model-ingredients-512-epoch-{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItFJ4j8VZ_En"
   },
   "source": [
    "#### im2instructions and instructions2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRCQMtF4aFbr"
   },
   "outputs": [],
   "source": [
    "instructions_dataset = EmbeddingDataset(img_train, instructions_train, neg_instructions_train)\n",
    "instructions_loader = DataLoader(instructions_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_model_instructions = EmbeddingNetwork(512)\n",
    "# img_model_instructions = nn.DataParallel(img_model_instructions, device_ids=[2,3])\n",
    "img_model_instructions.to(device);\n",
    "\n",
    "txt_model_instructions = EmbeddingNetwork(512);\n",
    "# txt_model_instructions = nn.DataParallel(txt_model_instructions, device_ids=[2,3])\n",
    "txt_model_instructions.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(list(img_model_instructions.parameters()) + list(txt_model_instructions.parameters()), lr=1e-2, weight_decay=0.0)\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "# criterion = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu: \n",
    "    criterion = criterion.to(device)\n",
    "    img_model_instructions = img_model_instructions.to(device)\n",
    "    txt_model_instructions = txt_model_instructions.to(device)\n",
    "    \n",
    "best_losses = 1e10\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(instructions_loader, img_model_instructions, txt_model_instructions, criterion, optimizer, epoch)\n",
    "        \n",
    "  # Save checkpoint and replace old best model if current model is betterabs\n",
    "torch.save(img_model_instructions.state_dict(), 'triplet_checkpoints/img-model-instructions-512-epoch-{}.pth'.format(epoch+1))\n",
    "torch.save(txt_model_instructions.state_dict(), 'triplet_checkpoints/txt-model-instructions-512-epoch-{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJFa2wqibUv6"
   },
   "source": [
    "### Training dims = 256; all components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NG0u8zdTbd1q"
   },
   "source": [
    "#### im2recipe and recipe2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0mRePqSbd1r"
   },
   "outputs": [],
   "source": [
    "train_dataset = EmbeddingDataset(img_train, text_train, neg_text_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_model = EmbeddingNetwork(256)\n",
    "# img_model= nn.DataParallel(img_model, device_ids=[2,3])\n",
    "img_model.to(device);\n",
    "\n",
    "txt_model = EmbeddingNetwork(256);\n",
    "# txt_model= nn.DataParallel(txt_model, device_ids=[2,3])\n",
    "txt_model.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(list(img_model.parameters()) + list(txt_model.parameters()), lr=1e-2, weight_decay=0.0)\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "# criterion = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu: \n",
    "    criterion = criterion.to(device)\n",
    "    img_model = img_model.to(device)\n",
    "    txt_model = txt_model.to(device)\n",
    "    \n",
    "best_losses = 1e10\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(train_loader, img_model, txt_model, criterion, optimizer, epoch)\n",
    "        \n",
    "  # Save checkpoint and replace old best model if current model is betterabs\n",
    "torch.save(img_model.state_dict(), 'triplet_checkpoints/img-model-full-256-epoch-{}.pth'.format(epoch+1))\n",
    "torch.save(txt_model.state_dict(), 'triplet_checkpoints/txt-model-full-256-epoch-{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHDEbCxBbd1s"
   },
   "source": [
    "#### im2title and title2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYGv68fYbd1s"
   },
   "outputs": [],
   "source": [
    "title_dataset = EmbeddingDataset(img_train, title_train, neg_title_train)\n",
    "title_loader = DataLoader(title_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_model_title = EmbeddingNetwork(256)\n",
    "# img_model_title = nn.DataParallel(img_model_title, device_ids=[2,3])\n",
    "img_model_title.to(device);\n",
    "\n",
    "txt_model_title = EmbeddingNetwork(256);\n",
    "# txt_model_title = nn.DataParallel(txt_model_title, device_ids=[2,3])\n",
    "txt_model_title.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(list(img_model_title.parameters()) + list(txt_model_title.parameters()), lr=1e-2, weight_decay=0.0)\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "# criterion = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu: \n",
    "    criterion = criterion.to(device)\n",
    "    img_model_title = img_model_title.to(device)\n",
    "    txt_model_title = txt_model_title.to(device)\n",
    "    \n",
    "best_losses = 1e10\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(title_loader, img_model_title, txt_model_title, criterion, optimizer, epoch)\n",
    "        \n",
    "  # Save checkpoint and replace old best model if current model is betterabs\n",
    "torch.save(img_model_title.state_dict(), 'triplet_checkpoints/img-model-title-256-epoch-{}.pth'.format(epoch+1))\n",
    "torch.save(txt_model_title.state_dict(), 'triplet_checkpoints/txt-model-title-256-epoch-{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dEJnEfwbd1s"
   },
   "source": [
    "#### im2ingredients and ingredients2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDmNColybd1t"
   },
   "outputs": [],
   "source": [
    "ingredients_dataset = EmbeddingDataset(img_train, ingredients_train, neg_ingredients_train)\n",
    "ingredients_loader = DataLoader(ingredients_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_model_ingredients = EmbeddingNetwork(256)\n",
    "# img_model_ingredients = nn.DataParallel(img_model_ingredients, device_ids=[2,3])\n",
    "img_model_ingredients.to(device);\n",
    "\n",
    "txt_model_ingredients = EmbeddingNetwork(256);\n",
    "# txt_model_ingredients = nn.DataParallel(txt_model_ingredients, device_ids=[2,3])\n",
    "txt_model_ingredients.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(list(img_model_ingredients.parameters()) + list(txt_model_ingredients.parameters()), lr=1e-2, weight_decay=0.0)\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "# criterion = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu: \n",
    "    criterion = criterion.to(device)\n",
    "    img_model_ingredients = img_model_ingredients.to(device)\n",
    "    txt_model_ingredients = txt_model_ingredients.to(device)\n",
    "    \n",
    "best_losses = 1e10\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(ingredients_loader, img_model_ingredients, txt_model_ingredients, criterion, optimizer, epoch)\n",
    "        \n",
    "  # Save checkpoint and replace old best model if current model is betterabs\n",
    "torch.save(img_model_ingredients.state_dict(), 'triplet_checkpoints/img-model-ingredients-256-epoch-{}.pth'.format(epoch+1))\n",
    "torch.save(txt_model_ingredients.state_dict(), 'triplet_checkpoints/txt-model-ingredients-256-epoch-{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrmGP00Wbd1t"
   },
   "source": [
    "#### im2instructions and instructions2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DU1gtziHbd1t"
   },
   "outputs": [],
   "source": [
    "instructions_dataset = EmbeddingDataset(img_train, instructions_train, neg_instructions_train)\n",
    "instructions_loader = DataLoader(instructions_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_model_instructions = EmbeddingNetwork(256)\n",
    "# img_model_instructions = nn.DataParallel(img_model_instructions, device_ids=[2,3])\n",
    "img_model_instructions.to(device);\n",
    "\n",
    "txt_model_instructions = EmbeddingNetwork(256);\n",
    "# txt_model_instructions = nn.DataParallel(txt_model_instructions, device_ids=[2,3])\n",
    "txt_model_instructions.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(list(img_model_instructions.parameters()) + list(txt_model_instructions.parameters()), lr=1e-2, weight_decay=0.0)\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "# criterion = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu: \n",
    "    criterion = criterion.to(device)\n",
    "    img_model_instructions = img_model_instructions.to(device)\n",
    "    txt_model_instructions = txt_model_instructions.to(device)\n",
    "    \n",
    "best_losses = 1e10\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(instructions_loader, img_model_instructions, txt_model_instructions, criterion, optimizer, epoch)\n",
    "        \n",
    "  # Save checkpoint and replace old best model if current model is betterabs\n",
    "torch.save(img_model_instructions.state_dict(), 'triplet_checkpoints/img-model-instructions-256-epoch-{}.pth'.format(epoch+1))\n",
    "torch.save(txt_model_instructions.state_dict(), 'triplet_checkpoints/txt-model-instructions-256-epoch-{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ItSD0uV1Ard"
   },
   "source": [
    "### Training dims = 128; all components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IifdpWPV1Are"
   },
   "source": [
    "#### im2recipe and recipe2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 2515,
     "status": "ok",
     "timestamp": 1649030300319,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "CGvdrrlB1Are"
   },
   "outputs": [],
   "source": [
    "train_dataset = EmbeddingDataset(img_train, text_train, neg_text_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_model = EmbeddingNetwork(128)\n",
    "# img_model= nn.DataParallel(img_model, device_ids=[2,3])\n",
    "img_model.to(device);\n",
    "\n",
    "txt_model = EmbeddingNetwork(128);\n",
    "# txt_model= nn.DataParallel(txt_model, device_ids=[2,3])\n",
    "txt_model.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(list(img_model.parameters()) + list(txt_model.parameters()), lr=1e-2, weight_decay=0.0)\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "# criterion = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu: \n",
    "    criterion = criterion.to(device)\n",
    "    img_model = img_model.to(device)\n",
    "    txt_model = txt_model.to(device)\n",
    "    \n",
    "best_losses = 1e10\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(train_loader, img_model, txt_model, criterion, optimizer, epoch)\n",
    "        \n",
    "  # Save checkpoint and replace old best model if current model is betterabs\n",
    "torch.save(img_model.state_dict(), 'triplet_checkpoints/img-model-full-128-epoch-{}.pth'.format(epoch+1))\n",
    "torch.save(txt_model.state_dict(), 'triplet_checkpoints/txt-model-full-128-epoch-{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bt8dset1Arf"
   },
   "source": [
    "#### im2title and title2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 4189,
     "status": "ok",
     "timestamp": 1649030535713,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "4hmKiCas1Arf"
   },
   "outputs": [],
   "source": [
    "title_dataset = EmbeddingDataset(img_train, title_train, neg_title_train)\n",
    "title_loader = DataLoader(title_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_model_title = EmbeddingNetwork(128)\n",
    "# img_model_title = nn.DataParallel(img_model_title, device_ids=[2,3])\n",
    "img_model_title.to(device);\n",
    "\n",
    "txt_model_title = EmbeddingNetwork(128);\n",
    "# txt_model_title = nn.DataParallel(txt_model_title, device_ids=[2,3])\n",
    "txt_model_title.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(list(img_model_title.parameters()) + list(txt_model_title.parameters()), lr=1e-2, weight_decay=0.0)\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "# criterion = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu: \n",
    "    criterion = criterion.to(device)\n",
    "    img_model_title = img_model_title.to(device)\n",
    "    txt_model_title = txt_model_title.to(device)\n",
    "    \n",
    "best_losses = 1e10\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(title_loader, img_model_title, txt_model_title, criterion, optimizer, epoch)\n",
    "        \n",
    "  # Save checkpoint and replace old best model if current model is betterabs\n",
    "torch.save(img_model_title.state_dict(), 'triplet_checkpoints/img-model-title-128-epoch-{}.pth'.format(epoch+1))\n",
    "torch.save(txt_model_title.state_dict(), 'triplet_checkpoints/txt-model-title-128-epoch-{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDEOr14V1Arg"
   },
   "source": [
    "#### im2ingredients and ingredients2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 4000,
     "status": "ok",
     "timestamp": 1649030650583,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "o2foU1QJ1Arg"
   },
   "outputs": [],
   "source": [
    "ingredients_dataset = EmbeddingDataset(img_train, ingredients_train, neg_ingredients_train)\n",
    "ingredients_loader = DataLoader(ingredients_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_model_ingredients = EmbeddingNetwork(128)\n",
    "# img_model_ingredients = nn.DataParallel(img_model_ingredients, device_ids=[2,3])\n",
    "img_model_ingredients.to(device);\n",
    "\n",
    "txt_model_ingredients = EmbeddingNetwork(128);\n",
    "# txt_model_ingredients = nn.DataParallel(txt_model_ingredients, device_ids=[2,3])\n",
    "txt_model_ingredients.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(list(img_model_ingredients.parameters()) + list(txt_model_ingredients.parameters()), lr=1e-2, weight_decay=0.0)\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "# criterion = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu: \n",
    "    criterion = criterion.to(device)\n",
    "    img_model_ingredients = img_model_ingredients.to(device)\n",
    "    txt_model_ingredients = txt_model_ingredients.to(device)\n",
    "    \n",
    "best_losses = 1e10\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(ingredients_loader, img_model_ingredients, txt_model_ingredients, criterion, optimizer, epoch)\n",
    "        \n",
    "  # Save checkpoint and replace old best model if current model is betterabs\n",
    "torch.save(img_model_ingredients.state_dict(), 'triplet_checkpoints/img-model-ingredients-128-epoch-{}.pth'.format(epoch+1))\n",
    "torch.save(txt_model_ingredients.state_dict(), 'triplet_checkpoints/txt-model-ingredients-128-epoch-{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfVhiOCX1Arh"
   },
   "source": [
    "#### im2instructions and instructions2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 2987,
     "status": "ok",
     "timestamp": 1649031047270,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "DGpHVBmQ1Arh"
   },
   "outputs": [],
   "source": [
    "instructions_dataset = EmbeddingDataset(img_train, instructions_train, neg_instructions_train)\n",
    "instructions_loader = DataLoader(instructions_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_model_instructions = EmbeddingNetwork(128)\n",
    "# img_model_instructions = nn.DataParallel(img_model_instructions, device_ids=[2,3])\n",
    "img_model_instructions.to(device);\n",
    "\n",
    "txt_model_instructions = EmbeddingNetwork(128);\n",
    "# txt_model_instructions = nn.DataParallel(txt_model_instructions, device_ids=[2,3])\n",
    "txt_model_instructions.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(list(img_model_instructions.parameters()) + list(txt_model_instructions.parameters()), lr=1e-2, weight_decay=0.0)\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "# criterion = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu: \n",
    "    criterion = criterion.to(device)\n",
    "    img_model_instructions = img_model_instructions.to(device)\n",
    "    txt_model_instructions = txt_model_instructions.to(device)\n",
    "    \n",
    "best_losses = 1e10\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(instructions_loader, img_model_instructions, txt_model_instructions, criterion, optimizer, epoch)\n",
    "        \n",
    "  # Save checkpoint and replace old best model if current model is betterabs\n",
    "torch.save(img_model_instructions.state_dict(), 'triplet_checkpoints/img-model-instructions-128-epoch-{}.pth'.format(epoch+1))\n",
    "torch.save(txt_model_instructions.state_dict(), 'triplet_checkpoints/txt-model-instructions-128-epoch-{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHLlq90yEXlV"
   },
   "source": [
    "### Training dims = 64; all components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4j-NZikmEXlW"
   },
   "source": [
    "#### im2recipe and recipe2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 3712,
     "status": "ok",
     "timestamp": 1649033905036,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "7ZeSMhQZEXlW"
   },
   "outputs": [],
   "source": [
    "train_dataset = EmbeddingDataset(img_train, text_train, neg_text_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_model = EmbeddingNetwork(64)\n",
    "# img_model= nn.DataParallel(img_model, device_ids=[2,3])\n",
    "img_model.to(device);\n",
    "\n",
    "txt_model = EmbeddingNetwork(64);\n",
    "# txt_model= nn.DataParallel(txt_model, device_ids=[2,3])\n",
    "txt_model.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(list(img_model.parameters()) + list(txt_model.parameters()), lr=1e-2, weight_decay=0.0)\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "# criterion = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu: \n",
    "    criterion = criterion.to(device)\n",
    "    img_model = img_model.to(device)\n",
    "    txt_model = txt_model.to(device)\n",
    "    \n",
    "best_losses = 1e10\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(train_loader, img_model, txt_model, criterion, optimizer, epoch)\n",
    "        \n",
    "  # Save checkpoint and replace old best model if current model is betterabs\n",
    "torch.save(img_model.state_dict(), 'triplet_checkpoints/img-model-full-64-epoch-{}.pth'.format(epoch+1))\n",
    "torch.save(txt_model.state_dict(), 'triplet_checkpoints/txt-model-full-64-epoch-{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drJFbwb6EXlX"
   },
   "source": [
    "#### im2title and title2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 5264,
     "status": "ok",
     "timestamp": 1649034144075,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "dXUVxhAiEXlX"
   },
   "outputs": [],
   "source": [
    "title_dataset = EmbeddingDataset(img_train, title_train, neg_title_train)\n",
    "title_loader = DataLoader(title_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_model_title = EmbeddingNetwork(64)\n",
    "# img_model_title = nn.DataParallel(img_model_title, device_ids=[2,3])\n",
    "img_model_title.to(device);\n",
    "\n",
    "txt_model_title = EmbeddingNetwork(64);\n",
    "# txt_model_title = nn.DataParallel(txt_model_title, device_ids=[2,3])\n",
    "txt_model_title.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(list(img_model_title.parameters()) + list(txt_model_title.parameters()), lr=1e-2, weight_decay=0.0)\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "# criterion = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu: \n",
    "    criterion = criterion.to(device)\n",
    "    img_model_title = img_model_title.to(device)\n",
    "    txt_model_title = txt_model_title.to(device)\n",
    "    \n",
    "best_losses = 1e10\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(title_loader, img_model_title, txt_model_title, criterion, optimizer, epoch)\n",
    "        \n",
    "  # Save checkpoint and replace old best model if current model is betterabs\n",
    "torch.save(img_model_title.state_dict(), 'triplet_checkpoints/img-model-title-64-epoch-{}.pth'.format(epoch+1))\n",
    "torch.save(txt_model_title.state_dict(), 'triplet_checkpoints/txt-model-title-64-epoch-{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjHmlZIKEXlY"
   },
   "source": [
    "#### im2ingredients and ingredients2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 2967,
     "status": "ok",
     "timestamp": 1649034481544,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "gpkF_qHUEXlY"
   },
   "outputs": [],
   "source": [
    "ingredients_dataset = EmbeddingDataset(img_train, ingredients_train, neg_ingredients_train)\n",
    "ingredients_loader = DataLoader(ingredients_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_model_ingredients = EmbeddingNetwork(64)\n",
    "# img_model_ingredients = nn.DataParallel(img_model_ingredients, device_ids=[2,3])\n",
    "img_model_ingredients.to(device);\n",
    "\n",
    "txt_model_ingredients = EmbeddingNetwork(64);\n",
    "# txt_model_ingredients = nn.DataParallel(txt_model_ingredients, device_ids=[2,3])\n",
    "txt_model_ingredients.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(list(img_model_ingredients.parameters()) + list(txt_model_ingredients.parameters()), lr=1e-2, weight_decay=0.0)\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "# criterion = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu: \n",
    "    criterion = criterion.to(device)\n",
    "    img_model_ingredients = img_model_ingredients.to(device)\n",
    "    txt_model_ingredients = txt_model_ingredients.to(device)\n",
    "    \n",
    "best_losses = 1e10\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(ingredients_loader, img_model_ingredients, txt_model_ingredients, criterion, optimizer, epoch)\n",
    "        \n",
    "  # Save checkpoint and replace old best model if current model is betterabs\n",
    "torch.save(img_model_ingredients.state_dict(), 'triplet_checkpoints/img-model-ingredients-64-epoch-{}.pth'.format(epoch+1))\n",
    "torch.save(txt_model_ingredients.state_dict(), 'triplet_checkpoints/txt-model-ingredients-64-epoch-{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Me2JGz91EXlZ"
   },
   "source": [
    "#### im2instructions and instructions2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 4417,
     "status": "ok",
     "timestamp": 1649034610320,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "4FEaYAv1EXlZ"
   },
   "outputs": [],
   "source": [
    "instructions_dataset = EmbeddingDataset(img_train, instructions_train, neg_instructions_train)\n",
    "instructions_loader = DataLoader(instructions_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_model_instructions = EmbeddingNetwork(64)\n",
    "# img_model_instructions = nn.DataParallel(img_model_instructions, device_ids=[2,3])\n",
    "img_model_instructions.to(device);\n",
    "\n",
    "txt_model_instructions = EmbeddingNetwork(64);\n",
    "# txt_model_instructions = nn.DataParallel(txt_model_instructions, device_ids=[2,3])\n",
    "txt_model_instructions.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(list(img_model_instructions.parameters()) + list(txt_model_instructions.parameters()), lr=1e-2, weight_decay=0.0)\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "# criterion = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu: \n",
    "    criterion = criterion.to(device)\n",
    "    img_model_instructions = img_model_instructions.to(device)\n",
    "    txt_model_instructions = txt_model_instructions.to(device)\n",
    "    \n",
    "best_losses = 1e10\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(instructions_loader, img_model_instructions, txt_model_instructions, criterion, optimizer, epoch)\n",
    "        \n",
    "  # Save checkpoint and replace old best model if current model is betterabs\n",
    "torch.save(img_model_instructions.state_dict(), 'triplet_checkpoints/img-model-instructions-64-epoch-{}.pth'.format(epoch+1))\n",
    "torch.save(txt_model_instructions.state_dict(), 'triplet_checkpoints/txt-model-instructions-64-epoch-{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6dfvKTPcWQ6"
   },
   "source": [
    "### Dimensional Analysis on val data. Dims: [64, 128, 256, 512]; all components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qM0qDgpcWQ6"
   },
   "source": [
    "#### 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hYt1DmICcWQ6"
   },
   "outputs": [],
   "source": [
    "# im2recipe 512\n",
    "img_model_full_512 = EmbeddingNetwork(512)\n",
    "# img_model_full_512 = nn.DataParallel(img_model_full_512, device_ids=[1])\n",
    "img_model_full_512.load_state_dict(torch.load(\"triplet_checkpoints/img-model-full-512-epoch-10.pth\"))\n",
    "# img_model_full_512.to((f'cuda:{img_model_full_512.device_ids[0]}'));\n",
    "img_model_full_512.to('cpu')\n",
    "img_model_full_512.eval();\n",
    "txt_model_full_512 = EmbeddingNetwork(512)\n",
    "# txt_model_full_512 = nn.DataParallel(txt_model_full_512, device_ids=[1])\n",
    "txt_model_full_512.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-full-512-epoch-10.pth\"))\n",
    "# txt_model_full_512.to((f'cuda:{txt_model_full_512.device_ids[0]}'));\n",
    "txt_model_full_512.to('cpu')\n",
    "txt_model_full_512.eval();\n",
    "\n",
    "# im2title 512\n",
    "img_model_title_512 = EmbeddingNetwork(512)\n",
    "# img_model_title_512 = nn.DataParallel(img_model_title_512, device_ids=[1])\n",
    "img_model_title_512.load_state_dict(torch.load(\"triplet_checkpoints/img-model-title-512-epoch-5.pth\"))\n",
    "# img_model_title_512.to((f'cuda:{img_model_title_512.device_ids[0]}'));\n",
    "img_model_title_512.to('cpu')\n",
    "img_model_title_512.eval();\n",
    "txt_model_title_512 = EmbeddingNetwork(512)\n",
    "# txt_model_title_512 = nn.DataParallel(txt_model_title_512, device_ids=[1])\n",
    "txt_model_title_512.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-title-512-epoch-5.pth\"))\n",
    "# txt_model_title_512.to((f'cuda:{txt_model_title_512.device_ids[0]}'));\n",
    "txt_model_title_512.to('cpu')\n",
    "txt_model_title_512.eval();\n",
    "\n",
    "# im2instructions 512\n",
    "img_model_instructions_512 = EmbeddingNetwork(512)\n",
    "# img_model_instructions_512 = nn.DataParallel(img_model_instructions_512, device_ids=[1])\n",
    "img_model_instructions_512.load_state_dict(torch.load(\"triplet_checkpoints/img-model-instructions-512-epoch-5.pth\"))\n",
    "# img_model_instructions_512.to((f'cuda:{img_model_instructions_512.device_ids[0]}'));\n",
    "img_model_instructions_512.to('cpu')\n",
    "img_model_instructions_512.eval();\n",
    "txt_model_instructions_512 = EmbeddingNetwork(512)\n",
    "# txt_model_instructions_512 = nn.DataParallel(txt_model_instructions_512, device_ids=[1])\n",
    "txt_model_instructions_512.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-instructions-512-epoch-5.pth\"))\n",
    "# txt_model_instructions_512.to((f'cuda:{txt_model_instructions_512.device_ids[0]}'));\n",
    "txt_model_instructions_512.to('cpu')\n",
    "txt_model_instructions_512.eval();\n",
    "\n",
    "#im2ingredients 512\n",
    "img_model_ingredients_512 = EmbeddingNetwork(512)\n",
    "# img_model_ingredients_512 = nn.DataParallel(img_model_ingredients_512, device_ids=[1])\n",
    "img_model_ingredients_512.load_state_dict(torch.load(\"triplet_checkpoints/img-model-ingredients-512-epoch-5.pth\"))\n",
    "# img_model_ingredients_512.to((f'cuda:{img_model_full_512.device_ids[0]}'));\n",
    "img_model_ingredients_512.to('cpu')\n",
    "img_model_ingredients_512.eval();\n",
    "txt_model_ingredients_512 = EmbeddingNetwork(512)\n",
    "# txt_model_ingredients_512 = nn.DataParallel(txt_model_ingredients_512, device_ids=[1])\n",
    "txt_model_ingredients_512.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-ingredients-512-epoch-5.pth\"))\n",
    "# txt_model_ingredients_512.to((f'cuda:{txt_model_ingredients_512.device_ids[0]}'));\n",
    "txt_model_ingredients_512.to('cpu')\n",
    "txt_model_ingredients_512.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 129596,
     "status": "ok",
     "timestamp": 1649015323447,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "1oFwAiDbcWQ6",
    "outputId": "4e31b690-7cd3-417b-fc0b-3ad4103d696b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2recipe for dims = 512 and sample = 1000\n",
      "Mean median 2.4\n",
      "Recall {1: 0.3538, 5: 0.6819, 10: 0.7863000000000001}\n",
      "Running im2recipe for dims = 512 and sample = 10000\n",
      "Mean median 15.9\n",
      "Recall {1: 0.10740000000000001, 5: 0.3032, 10: 0.41979}\n"
     ]
    }
   ],
   "source": [
    "img_val_nonlinear = np.zeros(shape = (len(img_val), 512))\n",
    "text_val_nonlinear = np.zeros(shape = (len(img_val), 512))\n",
    "\n",
    "# img_val_nonlinear.to(device)\n",
    "# text_val_nonlinear.to(device)\n",
    "\n",
    "for i in range(len(img_val)):\n",
    "    img_val_nonlinear[i] = img_model_full_512(torch.Tensor(np.expand_dims(img_val[i], 0))).detach().numpy()\n",
    "    text_val_nonlinear[i] = txt_model_full_512(torch.Tensor(np.expand_dims(text_val[i], 0))).detach().numpy()\n",
    "\n",
    "# im2recipe and recipe2im\n",
    "print(\"Running im2recipe for dims = 512 and sample = 1000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2recipe for dims = 512 and sample = 10000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 129819,
     "status": "ok",
     "timestamp": 1649015502927,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "2CSuJQu8cWQ7",
    "outputId": "9231b193-3490-4993-d712-7847c73e55e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2title for dims = 512 and sample = 1000\n",
      "Mean median 5.1\n",
      "Recall {1: 0.20360000000000006, 5: 0.5205, 10: 0.6624000000000001}\n",
      "Running im2title for dims = 512 and sample = 10000\n",
      "Mean median 42.3\n",
      "Recall {1: 0.043919999999999994, 5: 0.15214, 10: 0.23866}\n"
     ]
    }
   ],
   "source": [
    "img_val_nonlinear = np.zeros(shape = (len(img_val), 512))\n",
    "text_val_nonlinear = np.zeros(shape = (len(img_val), 512))\n",
    "\n",
    "for i in range(len(img_val)):\n",
    "    img_val_nonlinear[i] = img_model_title_512(torch.Tensor(np.expand_dims(img_val[i], 0))).detach().numpy()\n",
    "    text_val_nonlinear[i] = txt_model_title_512(torch.Tensor(np.expand_dims(text_val[i], 0))).detach().numpy()\n",
    "\n",
    "# im2title and title2im\n",
    "print(\"Running im2title for dims = 512 and sample = 1000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2title for dims = 512 and sample = 10000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 127634,
     "status": "ok",
     "timestamp": 1649015630555,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "2BJgBzSucWQ7",
    "outputId": "59153d5a-5d8e-4841-81ba-1a38721d6916"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2ingredients for dims = 512 and sample = 1000\n",
      "Mean median 4.1\n",
      "Recall {1: 0.263, 5: 0.5714999999999999, 10: 0.6995000000000001}\n",
      "Running im2ingredients for dims = 512 and sample = 10000\n",
      "Mean median 31.0\n",
      "Recall {1: 0.06504, 5: 0.20672000000000001, 10: 0.30518999999999996}\n"
     ]
    }
   ],
   "source": [
    "img_val_nonlinear = np.zeros(shape = (len(img_val), 512))\n",
    "text_val_nonlinear = np.zeros(shape = (len(img_val), 512))\n",
    "\n",
    "for i in range(len(img_val)):\n",
    "    img_val_nonlinear[i] = img_model_ingredients_512(torch.Tensor(np.expand_dims(img_val[i], 0))).detach().numpy()\n",
    "    text_val_nonlinear[i] = txt_model_ingredients_512(torch.Tensor(np.expand_dims(text_val[i], 0))).detach().numpy()\n",
    "\n",
    "# im2ingredients and ingredients2im\n",
    "print(\"Running im2ingredients for dims = 512 and sample = 1000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2ingredients for dims = 512 and sample = 10000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 127637,
     "status": "ok",
     "timestamp": 1649015758188,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "-WAb3W4tcWQ7",
    "outputId": "cae52ce6-dba0-42d5-91eb-60b367f22c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2instructions for dims = 512 and sample = 1000\n",
      "Mean median 3.0\n",
      "Recall {1: 0.3229, 5: 0.6366999999999999, 10: 0.7559}\n",
      "Running im2instructions for dims = 512 and sample = 10000\n",
      "Mean median 22.1\n",
      "Recall {1: 0.08642999999999999, 5: 0.25167, 10: 0.36322000000000004}\n"
     ]
    }
   ],
   "source": [
    "img_val_nonlinear = np.zeros(shape = (len(img_val), 512))\n",
    "text_val_nonlinear = np.zeros(shape = (len(img_val), 512))\n",
    "\n",
    "for i in range(len(img_val)):\n",
    "    img_val_nonlinear[i] = img_model_instructions_512(torch.Tensor(np.expand_dims(img_val[i], 0))).detach().numpy()\n",
    "    text_val_nonlinear[i] = txt_model_instructions_512(torch.Tensor(np.expand_dims(text_val[i], 0))).detach().numpy()\n",
    "\n",
    "# im2instructions and instructions2im\n",
    "print(\"Running im2instructions for dims = 512 and sample = 1000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2instructions for dims = 512 and sample = 10000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnBSnvR-cWQ7"
   },
   "source": [
    "#### 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPmZvQ0FcWQ7"
   },
   "outputs": [],
   "source": [
    "# im2recipe 256\n",
    "img_model_full_256 = EmbeddingNetwork(256)\n",
    "# img_model_full_256 = nn.DataParallel(img_model_full_256, device_ids=[1])\n",
    "img_model_full_256.load_state_dict(torch.load(\"triplet_checkpoints/img-model-full-256-epoch-10.pth\"))\n",
    "# img_model_full_256.to((f'cuda:{img_model_full_256.device_ids[0]}'));\n",
    "img_model_full_256.to('cpu')\n",
    "img_model_full_256.eval();\n",
    "txt_model_full_256 = EmbeddingNetwork(256)\n",
    "# txt_model_full_256 = nn.DataParallel(txt_model_full_256, device_ids=[1])\n",
    "txt_model_full_256.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-full-256-epoch-10.pth\"))\n",
    "# txt_model_full_256.to((f'cuda:{txt_model_full_256.device_ids[0]}'));\n",
    "txt_model_full_256.to('cpu')\n",
    "txt_model_full_256.eval();\n",
    "\n",
    "#im2title 256\n",
    "img_model_title_256 = EmbeddingNetwork(256)\n",
    "# img_model_title_256 = nn.DataParallel(img_model_title_256, device_ids=[1])\n",
    "img_model_title_256.load_state_dict(torch.load(\"triplet_checkpoints/img-model-title-256-epoch-5.pth\"))\n",
    "# img_model_title_256.to((f'cuda:{img_model_title_256.device_ids[0]}'));\n",
    "img_model_title_256.to('cpu')\n",
    "img_model_title_256.eval();\n",
    "txt_model_title_256 = EmbeddingNetwork(256)\n",
    "# txt_model_title_256 = nn.DataParallel(txt_model_title_256, device_ids=[1])\n",
    "txt_model_title_256.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-title-256-epoch-5.pth\"))\n",
    "# txt_model_title_256.to((f'cuda:{txt_model_title_256.device_ids[0]}'));\n",
    "txt_model_title_256.to('cpu')\n",
    "txt_model_title_256.eval();\n",
    "\n",
    "#im2instructions 256\n",
    "img_model_instructions_256 = EmbeddingNetwork(256)\n",
    "# img_model_instructions_256 = nn.DataParallel(img_model_instructions_256, device_ids=[1])\n",
    "img_model_instructions_256.load_state_dict(torch.load(\"triplet_checkpoints/img-model-instructions-256-epoch-5.pth\"))\n",
    "# img_model_instructions_256.to((f'cuda:{img_model_instructions_256.device_ids[0]}'));\n",
    "img_model_instructions_256.to('cpu')\n",
    "img_model_instructions_256.eval();\n",
    "txt_model_instructions_256 = EmbeddingNetwork(256)\n",
    "# txt_model_instructions_256 = nn.DataParallel(txt_model_instructions_256, device_ids=[1])\n",
    "txt_model_instructions_256.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-instructions-256-epoch-5.pth\"))\n",
    "# txt_model_instructions_256.to((f'cuda:{txt_model_instructions_256.device_ids[0]}'));\n",
    "txt_model_instructions_256.to('cpu')\n",
    "txt_model_instructions_256.eval();\n",
    "\n",
    "#im2ingredients 256\n",
    "img_model_ingredients_256 = EmbeddingNetwork(256)\n",
    "# img_model_ingredients_256 = nn.DataParallel(img_model_ingredients_256, device_ids=[1])\n",
    "img_model_ingredients_256.load_state_dict(torch.load(\"triplet_checkpoints/img-model-ingredients-256-epoch-5.pth\"))\n",
    "# img_model_ingredients_256.to((f'cuda:{img_model_full_256.device_ids[0]}'));\n",
    "img_model_ingredients_256.to('cpu')\n",
    "img_model_ingredients_256.eval();\n",
    "txt_model_ingredients_256 = EmbeddingNetwork(256)\n",
    "# txt_model_ingredients_256 = nn.DataParallel(txt_model_ingredients_256, device_ids=[1])\n",
    "txt_model_ingredients_256.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-ingredients-256-epoch-5.pth\"))\n",
    "# txt_model_ingredients_256.to((f'cuda:{txt_model_ingredients_256.device_ids[0]}'));\n",
    "txt_model_ingredients_256.to('cpu')\n",
    "txt_model_ingredients_256.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 121276,
     "status": "ok",
     "timestamp": 1649016644861,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "JSueVie1cWQ7",
    "outputId": "e4ee2461-7868-4827-e96c-7129eb32005a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2recipe for dims = 256 and sample = 1000\n",
      "Mean median 2.1\n",
      "Recall {1: 0.3718, 5: 0.697, 10: 0.7957}\n",
      "Running im2recipe for dims = 256 and sample = 10000\n",
      "Mean median 15.0\n",
      "Recall {1: 0.11236000000000002, 5: 0.31418, 10: 0.43373999999999996}\n"
     ]
    }
   ],
   "source": [
    "img_val_nonlinear = np.zeros(shape = (len(img_val), 256))\n",
    "text_val_nonlinear = np.zeros(shape = (len(img_val), 256))\n",
    "\n",
    "for i in range(len(img_val)):\n",
    "    img_val_nonlinear[i] = img_model_full_256(torch.Tensor(np.expand_dims(img_val[i], 0))).detach().numpy()\n",
    "    text_val_nonlinear[i] = txt_model_full_256(torch.Tensor(np.expand_dims(text_val[i], 0))).detach().numpy()\n",
    "\n",
    "# im2recipe and recipe2im\n",
    "print(\"Running im2recipe for dims = 256 and sample = 1000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2recipe for dims = 256 and sample = 10000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 120722,
     "status": "ok",
     "timestamp": 1649016765578,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "k3yjeIOKcWQ8",
    "outputId": "93fe49af-6c92-4525-fede-8e666f4c84bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2title for dims = 256 and sample = 1000\n",
      "Mean median 4.9\n",
      "Recall {1: 0.2165, 5: 0.5333, 10: 0.6711}\n",
      "Running im2title for dims = 256 and sample = 10000\n",
      "Mean median 39.5\n",
      "Recall {1: 0.04725999999999999, 5: 0.16085, 10: 0.24957}\n"
     ]
    }
   ],
   "source": [
    "img_val_nonlinear = np.zeros(shape = (len(img_val), 256))\n",
    "text_val_nonlinear = np.zeros(shape = (len(img_val), 256))\n",
    "\n",
    "for i in range(len(img_val)):\n",
    "    img_val_nonlinear[i] = img_model_title_256(torch.Tensor(np.expand_dims(img_val[i], 0))).detach().numpy()\n",
    "    text_val_nonlinear[i] = txt_model_title_256(torch.Tensor(np.expand_dims(text_val[i], 0))).detach().numpy()\n",
    "\n",
    "# im2title and title2im\n",
    "print(\"Running im2title for dims = 256 and sample = 1000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2title for dims = 256 and sample = 10000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 119767,
     "status": "ok",
     "timestamp": 1649016885339,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "8Az7ppSScWQ8",
    "outputId": "46449286-af9c-482b-b925-8713e875b3bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2ingredients for dims = 256 and sample = 1000\n",
      "Mean median 3.9\n",
      "Recall {1: 0.2761, 5: 0.5915, 10: 0.7167000000000001}\n",
      "Running im2ingredients for dims = 256 and sample = 10000\n",
      "Mean median 28.5\n",
      "Recall {1: 0.0715, 5: 0.22025999999999998, 10: 0.32059000000000004}\n"
     ]
    }
   ],
   "source": [
    "img_val_nonlinear = np.zeros(shape = (len(img_val), 256))\n",
    "text_val_nonlinear = np.zeros(shape = (len(img_val), 256))\n",
    "\n",
    "for i in range(len(img_val)):\n",
    "    img_val_nonlinear[i] = img_model_ingredients_256(torch.Tensor(np.expand_dims(img_val[i], 0))).detach().numpy()\n",
    "    text_val_nonlinear[i] = txt_model_ingredients_256(torch.Tensor(np.expand_dims(text_val[i], 0))).detach().numpy()\n",
    "\n",
    "# im2ingredients and ingredients2im\n",
    "print(\"Running im2ingredients for dims = 256 and sample = 1000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2ingredients for dims = 256 and sample = 10000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 121735,
     "status": "ok",
     "timestamp": 1649017069179,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "4JBT1OT_cWQ8",
    "outputId": "603329bc-db33-47bb-acb9-56b864ec5858"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2instructions for dims = 256 and sample = 1000\n",
      "Mean median 3.2\n",
      "Recall {1: 0.3028, 5: 0.6179, 10: 0.74}\n",
      "Running im2instructions for dims = 256 and sample = 10000\n",
      "Mean median 24.7\n",
      "Recall {1: 0.08179, 5: 0.24386000000000002, 10: 0.34886}\n"
     ]
    }
   ],
   "source": [
    "img_val_nonlinear = np.zeros(shape = (len(img_val), 256))\n",
    "text_val_nonlinear = np.zeros(shape = (len(img_val), 256))\n",
    "\n",
    "for i in range(len(img_val)):\n",
    "    img_val_nonlinear[i] = img_model_instructions_256(torch.Tensor(np.expand_dims(img_val[i], 0))).detach().numpy()\n",
    "    text_val_nonlinear[i] = txt_model_instructions_256(torch.Tensor(np.expand_dims(text_val[i], 0))).detach().numpy()\n",
    "\n",
    "# im2instructions and instructions2im\n",
    "print(\"Running im2instructions for dims = 256 and sample = 1000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2instructions for dims = 256 and sample = 10000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vECwGBaH6878"
   },
   "source": [
    "#### 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1649031864960,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "xlAC2C1o6879"
   },
   "outputs": [],
   "source": [
    "# im2recipe 128\n",
    "img_model_full_128 = EmbeddingNetwork(128)\n",
    "# img_model_full_128 = nn.DataParallel(img_model_full_128, device_ids=[1])\n",
    "img_model_full_128.load_state_dict(torch.load(\"triplet_checkpoints/img-model-full-128-epoch-10.pth\"))\n",
    "# img_model_full_128.to((f'cuda:{img_model_full_128.device_ids[0]}'));\n",
    "img_model_full_128.to('cpu')\n",
    "img_model_full_128.eval();\n",
    "txt_model_full_128 = EmbeddingNetwork(128)\n",
    "# txt_model_full_128 = nn.DataParallel(txt_model_full_128, device_ids=[1])\n",
    "txt_model_full_128.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-full-128-epoch-10.pth\"))\n",
    "# txt_model_full_128.to((f'cuda:{txt_model_full_128.device_ids[0]}'));\n",
    "txt_model_full_128.to('cpu')\n",
    "txt_model_full_128.eval();\n",
    "\n",
    "#im2title 128\n",
    "img_model_title_128 = EmbeddingNetwork(128)\n",
    "# img_model_title_128 = nn.DataParallel(img_model_title_128, device_ids=[1])\n",
    "img_model_title_128.load_state_dict(torch.load(\"triplet_checkpoints/img-model-title-128-epoch-5.pth\"))\n",
    "# img_model_title_128.to((f'cuda:{img_model_title_128.device_ids[0]}'));\n",
    "img_model_title_128.to('cpu')\n",
    "img_model_title_128.eval();\n",
    "txt_model_title_128 = EmbeddingNetwork(128)\n",
    "# txt_model_title_128 = nn.DataParallel(txt_model_title_128, device_ids=[1])\n",
    "txt_model_title_128.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-title-128-epoch-5.pth\"))\n",
    "# txt_model_title_128.to((f'cuda:{txt_model_title_128.device_ids[0]}'));\n",
    "txt_model_title_128.to('cpu')\n",
    "txt_model_title_128.eval();\n",
    "\n",
    "#im2instructions 128\n",
    "img_model_instructions_128 = EmbeddingNetwork(128)\n",
    "# img_model_instructions_128 = nn.DataParallel(img_model_instructions_128, device_ids=[1])\n",
    "img_model_instructions_128.load_state_dict(torch.load(\"triplet_checkpoints/img-model-instructions-128-epoch-5.pth\"))\n",
    "# img_model_instructions_128.to((f'cuda:{img_model_instructions_128.device_ids[0]}'));\n",
    "img_model_instructions_128.to('cpu')\n",
    "img_model_instructions_128.eval();\n",
    "txt_model_instructions_128 = EmbeddingNetwork(128)\n",
    "# txt_model_instructions_128 = nn.DataParallel(txt_model_instructions_128, device_ids=[1])\n",
    "txt_model_instructions_128.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-instructions-128-epoch-5.pth\"))\n",
    "# txt_model_instructions_128.to((f'cuda:{txt_model_instructions_128.device_ids[0]}'));\n",
    "txt_model_instructions_128.to('cpu')\n",
    "txt_model_instructions_128.eval();\n",
    "\n",
    "#im2ingredients 128\n",
    "img_model_ingredients_128 = EmbeddingNetwork(128)\n",
    "# img_model_ingredients_128 = nn.DataParallel(img_model_ingredients_128, device_ids=[1])\n",
    "img_model_ingredients_128.load_state_dict(torch.load(\"triplet_checkpoints/img-model-ingredients-128-epoch-5.pth\"))\n",
    "# img_model_ingredients_128.to((f'cuda:{img_model_full_128.device_ids[0]}'));\n",
    "img_model_ingredients_128.to('cpu')\n",
    "img_model_ingredients_128.eval();\n",
    "txt_model_ingredients_128 = EmbeddingNetwork(128)\n",
    "# txt_model_ingredients_128 = nn.DataParallel(txt_model_ingredients_128, device_ids=[1])\n",
    "txt_model_ingredients_128.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-ingredients-128-epoch-5.pth\"))\n",
    "# txt_model_ingredients_128.to((f'cuda:{txt_model_ingredients_128.device_ids[0]}'));\n",
    "txt_model_ingredients_128.to('cpu')\n",
    "txt_model_ingredients_128.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 136588,
     "status": "ok",
     "timestamp": 1649032006804,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "ZBvbKfnt6879",
    "outputId": "6f6dbc7e-38f3-485c-d932-3aad49b2922a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2recipe for dims = 128 and sample = 1000\n",
      "Mean median 2.0\n",
      "Recall {1: 0.3781, 5: 0.6936, 10: 0.797}\n",
      "Running im2recipe for dims = 128 and sample = 10000\n",
      "Mean median 13.9\n",
      "Recall {1: 0.12241000000000002, 5: 0.32748000000000005, 10: 0.44809}\n"
     ]
    }
   ],
   "source": [
    "img_val_nonlinear = np.zeros(shape = (len(img_val), 128))\n",
    "text_val_nonlinear = np.zeros(shape = (len(img_val), 128))\n",
    "\n",
    "for i in range(len(img_val)):\n",
    "    img_val_nonlinear[i] = img_model_full_128(torch.Tensor(np.expand_dims(img_val[i], 0))).detach().numpy()\n",
    "    text_val_nonlinear[i] = txt_model_full_128(torch.Tensor(np.expand_dims(text_val[i], 0))).detach().numpy()\n",
    "\n",
    "# im2recipe and recipe2im\n",
    "print(\"Running im2recipe for dims = 128 and sample = 1000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2recipe for dims = 128 and sample = 10000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135429,
     "status": "ok",
     "timestamp": 1649032142227,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "rtC8FIff6879",
    "outputId": "8c9a5fd2-0cfa-447e-f33a-245d3a71db5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2title for dims = 128 and sample = 1000\n",
      "Mean median 5.1\n",
      "Recall {1: 0.21220000000000003, 5: 0.5246000000000001, 10: 0.6697}\n",
      "Running im2title for dims = 128 and sample = 10000\n",
      "Mean median 41.6\n",
      "Recall {1: 0.04628, 5: 0.15596, 10: 0.24558}\n"
     ]
    }
   ],
   "source": [
    "img_val_nonlinear = np.zeros(shape = (len(img_val), 128))\n",
    "text_val_nonlinear = np.zeros(shape = (len(img_val), 128))\n",
    "\n",
    "for i in range(len(img_val)):\n",
    "    img_val_nonlinear[i] = img_model_title_128(torch.Tensor(np.expand_dims(img_val[i], 0))).detach().numpy()\n",
    "    text_val_nonlinear[i] = txt_model_title_128(torch.Tensor(np.expand_dims(text_val[i], 0))).detach().numpy()\n",
    "\n",
    "# im2title and title2im\n",
    "print(\"Running im2title for dims = 128 and sample = 1000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2title for dims = 128 and sample = 10000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135098,
     "status": "ok",
     "timestamp": 1649032277308,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "m947zI-u687-",
    "outputId": "b433f847-c4a5-4654-d443-2fd284bf665d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2ingredients for dims = 128 and sample = 1000\n",
      "Mean median 3.85\n",
      "Recall {1: 0.26820000000000005, 5: 0.5885, 10: 0.7089000000000001}\n",
      "Running im2ingredients for dims = 128 and sample = 10000\n",
      "Mean median 29.0\n",
      "Recall {1: 0.06841, 5: 0.21638000000000002, 10: 0.31759000000000004}\n"
     ]
    }
   ],
   "source": [
    "img_val_nonlinear = np.zeros(shape = (len(img_val), 128))\n",
    "text_val_nonlinear = np.zeros(shape = (len(img_val), 128))\n",
    "\n",
    "for i in range(len(img_val)):\n",
    "    img_val_nonlinear[i] = img_model_ingredients_128(torch.Tensor(np.expand_dims(img_val[i], 0))).detach().numpy()\n",
    "    text_val_nonlinear[i] = txt_model_ingredients_128(torch.Tensor(np.expand_dims(text_val[i], 0))).detach().numpy()\n",
    "\n",
    "# im2ingredients and ingredients2im\n",
    "print(\"Running im2ingredients for dims = 128 and sample = 1000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2ingredients for dims = 128 and sample = 10000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135474,
     "status": "ok",
     "timestamp": 1649032412775,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "ylXZ62uz687-",
    "outputId": "15cfbc5c-9476-41ab-8906-9dba7cc5819a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2instructions for dims = 128 and sample = 1000\n",
      "Mean median 3.0\n",
      "Recall {1: 0.32460000000000006, 5: 0.6363, 10: 0.7506}\n",
      "Running im2instructions for dims = 128 and sample = 10000\n",
      "Mean median 21.8\n",
      "Recall {1: 0.08918000000000001, 5: 0.25699000000000005, 10: 0.36541}\n"
     ]
    }
   ],
   "source": [
    "img_val_nonlinear = np.zeros(shape = (len(img_val), 128))\n",
    "text_val_nonlinear = np.zeros(shape = (len(img_val), 128))\n",
    "\n",
    "for i in range(len(img_val)):\n",
    "    img_val_nonlinear[i] = img_model_instructions_128(torch.Tensor(np.expand_dims(img_val[i], 0))).detach().numpy()\n",
    "    text_val_nonlinear[i] = txt_model_instructions_128(torch.Tensor(np.expand_dims(text_val[i], 0))).detach().numpy()\n",
    "\n",
    "# im2instructions and instructions2im\n",
    "print(\"Running im2instructions for dims = 128 and sample = 1000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2instructions for dims = 128 and sample = 10000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_LUL7UgAaf4"
   },
   "source": [
    "#### 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1649034771619,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "ZiWv8IjCAaf5"
   },
   "outputs": [],
   "source": [
    "# im2recipe 64\n",
    "img_model_full_64 = EmbeddingNetwork(64)\n",
    "# img_model_full_64 = nn.DataParallel(img_model_full_64, device_ids=[1])\n",
    "img_model_full_64.load_state_dict(torch.load(\"triplet_checkpoints/img-model-full-64-epoch-10.pth\"))\n",
    "# img_model_full_64.to((f'cuda:{img_model_full_64.device_ids[0]}'));\n",
    "img_model_full_64.to('cpu')\n",
    "img_model_full_64.eval();\n",
    "txt_model_full_64 = EmbeddingNetwork(64)\n",
    "# txt_model_full_64 = nn.DataParallel(txt_model_full_64, device_ids=[1])\n",
    "txt_model_full_64.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-full-64-epoch-10.pth\"))\n",
    "# txt_model_full_64.to((f'cuda:{txt_model_full_64.device_ids[0]}'));\n",
    "txt_model_full_64.to('cpu')\n",
    "txt_model_full_64.eval();\n",
    "\n",
    "#im2title 64\n",
    "img_model_title_64 = EmbeddingNetwork(64)\n",
    "# img_model_title_64 = nn.DataParallel(img_model_title_64, device_ids=[1])\n",
    "img_model_title_64.load_state_dict(torch.load(\"triplet_checkpoints/img-model-title-64-epoch-5.pth\"))\n",
    "# img_model_title_64.to((f'cuda:{img_model_title_64.device_ids[0]}'));\n",
    "img_model_title_64.to('cpu')\n",
    "img_model_title_64.eval();\n",
    "txt_model_title_64 = EmbeddingNetwork(64)\n",
    "# txt_model_title_64 = nn.DataParallel(txt_model_title_64, device_ids=[1])\n",
    "txt_model_title_64.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-title-64-epoch-5.pth\"))\n",
    "# txt_model_title_64.to((f'cuda:{txt_model_title_64.device_ids[0]}'));\n",
    "txt_model_title_64.to('cpu')\n",
    "txt_model_title_64.eval();\n",
    "\n",
    "#im2instructions 64\n",
    "img_model_instructions_64 = EmbeddingNetwork(64)\n",
    "# img_model_instructions_64 = nn.DataParallel(img_model_instructions_64, device_ids=[1])\n",
    "img_model_instructions_64.load_state_dict(torch.load(\"triplet_checkpoints/img-model-instructions-64-epoch-5.pth\"))\n",
    "# img_model_instructions_64.to((f'cuda:{img_model_instructions_64.device_ids[0]}'));\n",
    "img_model_instructions_64.to('cpu')\n",
    "img_model_instructions_64.eval();\n",
    "txt_model_instructions_64 = EmbeddingNetwork(64)\n",
    "# txt_model_instructions_64 = nn.DataParallel(txt_model_instructions_64, device_ids=[1])\n",
    "txt_model_instructions_64.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-instructions-64-epoch-5.pth\"))\n",
    "# txt_model_instructions_64.to((f'cuda:{txt_model_instructions_64.device_ids[0]}'));\n",
    "txt_model_instructions_64.to('cpu')\n",
    "txt_model_instructions_64.eval();\n",
    "\n",
    "#im2ingredients 64\n",
    "img_model_ingredients_64 = EmbeddingNetwork(64)\n",
    "# img_model_ingredients_64 = nn.DataParallel(img_model_ingredients_64, device_ids=[1])\n",
    "img_model_ingredients_64.load_state_dict(torch.load(\"triplet_checkpoints/img-model-ingredients-64-epoch-5.pth\"))\n",
    "# img_model_ingredients_64.to((f'cuda:{img_model_full_64.device_ids[0]}'));\n",
    "img_model_ingredients_64.to('cpu')\n",
    "img_model_ingredients_64.eval();\n",
    "txt_model_ingredients_64 = EmbeddingNetwork(64)\n",
    "# txt_model_ingredients_64 = nn.DataParallel(txt_model_ingredients_64, device_ids=[1])\n",
    "txt_model_ingredients_64.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-ingredients-64-epoch-5.pth\"))\n",
    "# txt_model_ingredients_64.to((f'cuda:{txt_model_ingredients_64.device_ids[0]}'));\n",
    "txt_model_ingredients_64.to('cpu')\n",
    "txt_model_ingredients_64.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135342,
     "status": "ok",
     "timestamp": 1649034913210,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "DBfP6O6zAaf5",
    "outputId": "6dae4b2b-1d3b-493a-dbb3-5503b0f7e956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2recipe for dims = 64 and sample = 1000\n",
      "Mean median 2.4\n",
      "Recall {1: 0.35960000000000003, 5: 0.6848, 10: 0.7952}\n",
      "Running im2recipe for dims = 64 and sample = 10000\n",
      "Mean median 14.9\n",
      "Recall {1: 0.11610999999999998, 5: 0.31612999999999997, 10: 0.43578}\n"
     ]
    }
   ],
   "source": [
    "img_val_nonlinear = np.zeros(shape = (len(img_val), 64))\n",
    "text_val_nonlinear = np.zeros(shape = (len(img_val), 64))\n",
    "\n",
    "for i in range(len(img_val)):\n",
    "    img_val_nonlinear[i] = img_model_full_64(torch.Tensor(np.expand_dims(img_val[i], 0))).detach().numpy()\n",
    "    text_val_nonlinear[i] = txt_model_full_64(torch.Tensor(np.expand_dims(text_val[i], 0))).detach().numpy()\n",
    "\n",
    "# im2recipe and recipe2im\n",
    "print(\"Running im2recipe for dims = 64 and sample = 1000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2recipe for dims = 64 and sample = 10000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 133976,
     "status": "ok",
     "timestamp": 1649035047180,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "t2GcFP2cAaf6",
    "outputId": "27054508-7b48-47fb-f74d-e43347e77449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2title for dims = 64 and sample = 1000\n",
      "Mean median 4.9\n",
      "Recall {1: 0.21749999999999997, 5: 0.5327999999999999, 10: 0.6723}\n",
      "Running im2title for dims = 64 and sample = 10000\n",
      "Mean median 39.25\n",
      "Recall {1: 0.046579999999999996, 5: 0.16155, 10: 0.25102}\n"
     ]
    }
   ],
   "source": [
    "img_val_nonlinear = np.zeros(shape = (len(img_val), 64))\n",
    "text_val_nonlinear = np.zeros(shape = (len(img_val), 64))\n",
    "\n",
    "for i in range(len(img_val)):\n",
    "    img_val_nonlinear[i] = img_model_title_64(torch.Tensor(np.expand_dims(img_val[i], 0))).detach().numpy()\n",
    "    text_val_nonlinear[i] = txt_model_title_64(torch.Tensor(np.expand_dims(text_val[i], 0))).detach().numpy()\n",
    "\n",
    "# im2title and title2im\n",
    "print(\"Running im2title for dims = 64 and sample = 1000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2title for dims = 64 and sample = 10000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 132807,
     "status": "ok",
     "timestamp": 1649035179981,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "rXLCj98XAaf6",
    "outputId": "9a149738-971c-4f23-cd35-d05218dcba07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2ingredients for dims = 64 and sample = 1000\n",
      "Mean median 4.0\n",
      "Recall {1: 0.269, 5: 0.5833999999999999, 10: 0.7110999999999998}\n",
      "Running im2ingredients for dims = 64 and sample = 10000\n",
      "Mean median 28.6\n",
      "Recall {1: 0.07246999999999999, 5: 0.22054, 10: 0.32203}\n"
     ]
    }
   ],
   "source": [
    "img_val_nonlinear = np.zeros(shape = (len(img_val), 64))\n",
    "text_val_nonlinear = np.zeros(shape = (len(img_val), 64))\n",
    "\n",
    "for i in range(len(img_val)):\n",
    "    img_val_nonlinear[i] = img_model_ingredients_64(torch.Tensor(np.expand_dims(img_val[i], 0))).detach().numpy()\n",
    "    text_val_nonlinear[i] = txt_model_ingredients_64(torch.Tensor(np.expand_dims(text_val[i], 0))).detach().numpy()\n",
    "\n",
    "# im2ingredients and ingredients2im\n",
    "print(\"Running im2ingredients for dims = 64 and sample = 1000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2ingredients for dims = 64 and sample = 10000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 132760,
     "status": "ok",
     "timestamp": 1649035312734,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "9uE4CUEVAaf6",
    "outputId": "6edb18b6-02b5-4bd3-aa55-21686c0cedfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2instructions for dims = 64 and sample = 1000\n",
      "Mean median 3.0\n",
      "Recall {1: 0.3296, 5: 0.6529, 10: 0.7682}\n",
      "Running im2instructions for dims = 64 and sample = 10000\n",
      "Mean median 20.0\n",
      "Recall {1: 0.09388999999999999, 5: 0.27048000000000005, 10: 0.38217}\n"
     ]
    }
   ],
   "source": [
    "img_val_nonlinear = np.zeros(shape = (len(img_val), 64))\n",
    "text_val_nonlinear = np.zeros(shape = (len(img_val), 64))\n",
    "\n",
    "for i in range(len(img_val)):\n",
    "    img_val_nonlinear[i] = img_model_instructions_64(torch.Tensor(np.expand_dims(img_val[i], 0))).detach().numpy()\n",
    "    text_val_nonlinear[i] = txt_model_instructions_64(torch.Tensor(np.expand_dims(text_val[i], 0))).detach().numpy()\n",
    "\n",
    "# im2instructions and instructions2im\n",
    "print(\"Running im2instructions for dims = 64 and sample = 1000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2instructions for dims = 64 and sample = 10000\")\n",
    "ranker(img_val_nonlinear, text_val_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPyjz3lqeyx7"
   },
   "source": [
    "### Evaluation and Ablation Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mO28plXEeyx8"
   },
   "source": [
    " We can see that dimensions = 256 has a better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AdWuciK8GbHh"
   },
   "outputs": [],
   "source": [
    "# im2recipe 256\n",
    "img_model_full_256 = EmbeddingNetwork(256)\n",
    "# img_model_full_256 = nn.DataParallel(img_model_full_256, device_ids=[1])\n",
    "img_model_full_256.load_state_dict(torch.load(\"triplet_checkpoints/img-model-full-256-epoch-10.pth\"))\n",
    "# img_model_full_256.to((f'cuda:{img_model_full_256.device_ids[0]}'));\n",
    "img_model_full_256.to('cpu')\n",
    "img_model_full_256.eval();\n",
    "txt_model_full_256 = EmbeddingNetwork(256)\n",
    "# txt_model_full_256 = nn.DataParallel(txt_model_full_256, device_ids=[1])\n",
    "txt_model_full_256.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-full-256-epoch-10.pth\"))\n",
    "# txt_model_full_256.to((f'cuda:{txt_model_full_256.device_ids[0]}'));\n",
    "txt_model_full_256.to('cpu')\n",
    "txt_model_full_256.eval();\n",
    "\n",
    "#im2title 256\n",
    "img_model_title_256 = EmbeddingNetwork(256)\n",
    "# img_model_title_256 = nn.DataParallel(img_model_title_256, device_ids=[1])\n",
    "img_model_title_256.load_state_dict(torch.load(\"triplet_checkpoints/img-model-title-256-epoch-5.pth\"))\n",
    "# img_model_title_256.to((f'cuda:{img_model_title_256.device_ids[0]}'));\n",
    "img_model_title_256.to('cpu')\n",
    "img_model_title_256.eval();\n",
    "txt_model_title_256 = EmbeddingNetwork(256)\n",
    "# txt_model_title_256 = nn.DataParallel(txt_model_title_256, device_ids=[1])\n",
    "txt_model_title_256.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-title-256-epoch-5.pth\"))\n",
    "# txt_model_title_256.to((f'cuda:{txt_model_title_256.device_ids[0]}'));\n",
    "txt_model_title_256.to('cpu')\n",
    "txt_model_title_256.eval();\n",
    "\n",
    "#im2instructions 256\n",
    "img_model_instructions_256 = EmbeddingNetwork(256)\n",
    "# img_model_instructions_256 = nn.DataParallel(img_model_instructions_256, device_ids=[1])\n",
    "img_model_instructions_256.load_state_dict(torch.load(\"triplet_checkpoints/img-model-instructions-256-epoch-5.pth\"))\n",
    "# img_model_instructions_256.to((f'cuda:{img_model_instructions_256.device_ids[0]}'));\n",
    "img_model_instructions_256.to('cpu')\n",
    "img_model_instructions_256.eval();\n",
    "txt_model_instructions_256 = EmbeddingNetwork(256)\n",
    "# txt_model_instructions_256 = nn.DataParallel(txt_model_instructions_256, device_ids=[1])\n",
    "txt_model_instructions_256.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-instructions-256-epoch-5.pth\"))\n",
    "# txt_model_instructions_256.to((f'cuda:{txt_model_instructions_256.device_ids[0]}'));\n",
    "txt_model_instructions_256.to('cpu')\n",
    "txt_model_instructions_256.eval();\n",
    "\n",
    "#im2ingredients 256\n",
    "img_model_ingredients_256 = EmbeddingNetwork(256)\n",
    "# img_model_ingredients_256 = nn.DataParallel(img_model_ingredients_256, device_ids=[1])\n",
    "img_model_ingredients_256.load_state_dict(torch.load(\"triplet_checkpoints/img-model-ingredients-256-epoch-5.pth\"))\n",
    "# img_model_ingredients_256.to((f'cuda:{img_model_full_256.device_ids[0]}'));\n",
    "img_model_ingredients_256.to('cpu')\n",
    "img_model_ingredients_256.eval();\n",
    "txt_model_ingredients_256 = EmbeddingNetwork(256)\n",
    "# txt_model_ingredients_256 = nn.DataParallel(txt_model_ingredients_256, device_ids=[1])\n",
    "txt_model_ingredients_256.load_state_dict(torch.load(\"triplet_checkpoints/txt-model-ingredients-256-epoch-5.pth\"))\n",
    "# txt_model_ingredients_256.to((f'cuda:{txt_model_ingredients_256.device_ids[0]}'));\n",
    "txt_model_ingredients_256.to('cpu')\n",
    "txt_model_ingredients_256.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 120205,
     "status": "ok",
     "timestamp": 1649017853954,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "AjVNutS7GbHi",
    "outputId": "17530e59-4998-4ff3-ea99-7c23dee0799e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2recipe for dims = 256 and sample = 1000\n",
      "Mean median 2.0\n",
      "Recall {1: 0.3794, 5: 0.6984, 10: 0.7993}\n",
      "Running im2recipe for dims = 256 and sample = 10000\n",
      "Mean median 15.1\n",
      "Recall {1: 0.11216, 5: 0.31331000000000003, 10: 0.43186}\n"
     ]
    }
   ],
   "source": [
    "img_test_nonlinear = np.zeros(shape = (len(img_test), 256))\n",
    "text_test_nonlinear = np.zeros(shape = (len(img_test), 256))\n",
    "\n",
    "for i in range(len(img_test)):\n",
    "    img_test_nonlinear[i] = img_model_full_256(torch.Tensor(np.expand_dims(img_test[i], 0))).detach().numpy()\n",
    "    text_test_nonlinear[i] = txt_model_full_256(torch.Tensor(np.expand_dims(text_test[i], 0))).detach().numpy()\n",
    "\n",
    "# im2recipe and recipe2im\n",
    "print(\"Running im2recipe for dims = 256 and sample = 1000\")\n",
    "ranker(img_test_nonlinear, text_test_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2recipe for dims = 256 and sample = 10000\")\n",
    "ranker(img_test_nonlinear, text_test_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 119823,
     "status": "ok",
     "timestamp": 1649017973771,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "NpulaqACGbHi",
    "outputId": "fc59928a-1e1e-44dc-e2fa-f4671fd22285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2title for dims = 256 and sample = 1000\n",
      "Mean median 4.85\n",
      "Recall {1: 0.217, 5: 0.5293, 10: 0.665}\n",
      "Running im2title for dims = 256 and sample = 10000\n",
      "Mean median 40.25\n",
      "Recall {1: 0.04741000000000001, 5: 0.16038000000000002, 10: 0.25114000000000003}\n"
     ]
    }
   ],
   "source": [
    "img_test_nonlinear = np.zeros(shape = (len(img_test), 256))\n",
    "text_test_nonlinear = np.zeros(shape = (len(img_test), 256))\n",
    "\n",
    "for i in range(len(img_test)):\n",
    "    img_test_nonlinear[i] = img_model_title_256(torch.Tensor(np.expand_dims(img_test[i], 0))).detach().numpy()\n",
    "    text_test_nonlinear[i] = txt_model_title_256(torch.Tensor(np.expand_dims(text_test[i], 0))).detach().numpy()\n",
    "\n",
    "# im2title and title2im\n",
    "print(\"Running im2title for dims = 256 and sample = 1000\")\n",
    "ranker(img_test_nonlinear, text_test_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2title for dims = 256 and sample = 10000\")\n",
    "ranker(img_test_nonlinear, text_test_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 119788,
     "status": "ok",
     "timestamp": 1649018093552,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "-2PrXGGmGbHj",
    "outputId": "9a4acffb-c9b0-4254-e382-9e9e8b069310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2ingredients for dims = 256 and sample = 1000\n",
      "Mean median 3.8\n",
      "Recall {1: 0.276, 5: 0.5836, 10: 0.7084}\n",
      "Running im2ingredients for dims = 256 and sample = 10000\n",
      "Mean median 28.4\n",
      "Recall {1: 0.07182999999999999, 5: 0.22010000000000002, 10: 0.31999}\n"
     ]
    }
   ],
   "source": [
    "img_test_nonlinear = np.zeros(shape = (len(img_test), 256))\n",
    "text_test_nonlinear = np.zeros(shape = (len(img_test), 256))\n",
    "\n",
    "for i in range(len(img_test)):\n",
    "    img_test_nonlinear[i] = img_model_ingredients_256(torch.Tensor(np.expand_dims(img_test[i], 0))).detach().numpy()\n",
    "    text_test_nonlinear[i] = txt_model_ingredients_256(torch.Tensor(np.expand_dims(text_test[i], 0))).detach().numpy()\n",
    "\n",
    "# im2ingredients and ingredients2im\n",
    "print(\"Running im2ingredients for dims = 256 and sample = 1000\")\n",
    "ranker(img_test_nonlinear, text_test_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2ingredients for dims = 256 and sample = 10000\")\n",
    "ranker(img_test_nonlinear, text_test_nonlinear, 10000, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 120233,
     "status": "ok",
     "timestamp": 1649018213778,
     "user": {
      "displayName": "Neil Pillai",
      "userId": "06533696322730179220"
     },
     "user_tz": 240
    },
    "id": "ylC0AKqYGbHj",
    "outputId": "bd955450-3ff2-43e5-8bec-7466a4faec6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running im2instructions for dims = 256 and sample = 1000\n",
      "Mean median 3.4\n",
      "Recall {1: 0.29660000000000003, 5: 0.6060999999999999, 10: 0.7335}\n",
      "Running im2instructions for dims = 256 and sample = 10000\n",
      "Mean median 24.7\n",
      "Recall {1: 0.07762, 5: 0.23694999999999994, 10: 0.34320000000000006}\n"
     ]
    }
   ],
   "source": [
    "img_test_nonlinear = np.zeros(shape = (len(img_test), 256))\n",
    "text_test_nonlinear = np.zeros(shape = (len(img_test), 256))\n",
    "\n",
    "for i in range(len(img_test)):\n",
    "    img_test_nonlinear[i] = img_model_instructions_256(torch.Tensor(np.expand_dims(img_test[i], 0))).detach().numpy()\n",
    "    text_test_nonlinear[i] = txt_model_instructions_256(torch.Tensor(np.expand_dims(text_test[i], 0))).detach().numpy()\n",
    "\n",
    "# im2instructions and instructions2im\n",
    "print(\"Running im2instructions for dims = 256 and sample = 1000\")\n",
    "ranker(img_test_nonlinear, text_test_nonlinear, 1000, \"image\")\n",
    "print(\"Running im2instructions for dims = 256 and sample = 10000\")\n",
    "ranker(img_test_nonlinear, text_test_nonlinear, 10000, \"image\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "022f6705",
    "64b12673-5d63-45c2-9090-2179bc0b2fb0",
    "38a4ee6f-1b30-4f88-ba4f-d0015d283cf7",
    "5f0e6af1-ebb9-4a04-bead-4bf7618cd04e",
    "557c8295-86c4-4a71-a669-bb8bc7cc5425",
    "4e9b4352-7e5b-4983-a933-a2d78daa2ae7",
    "2606fc14-019e-40da-8e96-bb575671d842",
    "c9804e73-7c90-4b09-a40e-1a83cdf7e514",
    "dbccae98-d1ef-4f5f-9668-04c101da262e",
    "927d6eaf-f99d-4111-b06b-b531501ada61",
    "1cc8ca56-6956-47ff-9ee5-7012a23b6311",
    "c07e2117-8725-4dc4-9f9a-b874d21e853b",
    "ff253dc1-1f1c-4669-ba8f-ffec14253e51",
    "2a1658c8-da88-427c-9736-5ccf1db5a2cc",
    "87eb3196-262a-4e57-b2fa-80c2cd02cd19",
    "df7f444d-cfff-43ec-97dc-c92d837a69d2",
    "3c05f885",
    "75afd4aa",
    "f9add441",
    "9663baa6",
    "3062b9f9",
    "364fd19b",
    "37c7aeb7",
    "lTmZH8KqLWWN",
    "6Rr1WETBLWWO",
    "GFMxYQRpLWWO",
    "ad96b882",
    "296c17c0",
    "5c60c319",
    "6fa626f8",
    "HM8VRH7HiStf",
    "aVzakDA6UG_p",
    "b0mMr_cyVXn6",
    "vzdCubAmYl9T",
    "ItFJ4j8VZ_En",
    "KJFa2wqibUv6",
    "NG0u8zdTbd1q",
    "FHDEbCxBbd1s",
    "-dEJnEfwbd1s",
    "qrmGP00Wbd1t",
    "IifdpWPV1Are",
    "0bt8dset1Arf",
    "KDEOr14V1Arg",
    "YfVhiOCX1Arh",
    "4j-NZikmEXlW",
    "drJFbwb6EXlX",
    "9qM0qDgpcWQ6",
    "vECwGBaH6878",
    "BPyjz3lqeyx7"
   ],
   "machine_shape": "hm",
   "name": "CCA and Ablation (new).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
